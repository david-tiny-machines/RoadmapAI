# v0.0.5d Implementation Plan: Implement Full MVP Conversation Flow & State Management

## Overview

This version focuses on enhancing the backend API logic to guide the user through all sections defined in the MVP scope (Overview, simplified Product Requirements, Risks/Assumptions) and maintaining the conversation state between requests.

1.  **Backend State Management:** Implement a simple mechanism (e.g., in-memory store) on the backend (`pages/api/agents/prd-generator.ts`) to store and retrieve the conversation history for a given user session.
2.  **Refined Prompt Engineering:** Update the system prompt and the way message history is sent to the OpenAI API to encourage the AI to guide the conversation sequentially through the MVP sections.
3.  **Conversation Logic Enhancement:** Rely on the improved prompt and the AI's conversational abilities to ask relevant questions for each section and transition appropriately based on the history provided.

## Prerequisites

-   Completion of `v0.0.5c` (Frontend connected to backend, basic conversation working).
-   Access to the application development environment (Replit).
-   Access to the codebase.
-   OpenAI API Key configured.

## Test Environment

-   Browser: Chrome latest version (or any modern browser).
-   User Accounts: Standard authenticated user access.
-   Browser Developer Tools (Network tab, Console tab).
-   Replit Console (for backend logs/debugging).

## Database Updates

-   None required for this version. Conversation state will be managed in-memory on the backend for simplicity.
    *Note: This means conversation history will be lost if the server restarts. Persistent storage (e.g., using Supabase) can be added later.* 

## Component & Configuration Updates

1.  **API Route (`pages/api/agents/prd-generator.ts`):**
    *   **Action:** Major refactoring of the handler function.
    *   **Details:**
        *   **Session Store:** Implement a simple in-memory store (e.g., a `Map` object at the module level) to hold conversation history. `const sessionStore = new Map<string, ChatMessage[]>();`
        *   **Session Key:** Determine a way to identify the user session (e.g., for now, could use a hardcoded key for testing, or ideally extract the authenticated Supabase user ID if easily accessible within the API route via helpers).
        *   **History Management:**
            *   At the start of a request, retrieve the existing message history for the session key from the `sessionStore`. If none exists, initialize it (e.g., with just the system prompt).
            *   Append the new user message(s) from the request body (`req.body.messages`) to the retrieved history.
            *   Update the `sessionStore` with the latest history *before* sending the response back.
        *   **Prompt Engineering:**
            *   Modify the initial `systemPrompt` to better instruct the AI on its role: guide the user through generating an MVP PRD covering Overview (Exec Summary, Problems, Segments), simplified Requirements (Solution Summary, Metrics), and Risks/Assumptions. Explicitly ask it to move from one section to the next when appropriate.
            *   Ensure the *entire updated conversation history* (including the system prompt and the latest user message) is passed to the `openai.chat.completions.create` call.
        *   **AI Response Handling:**
            *   After getting the reply from OpenAI, create the assistant message object.
            *   Append the assistant's message to the session's history in the `sessionStore`.
            *   Return only the latest assistant reply content (`{ reply: replyContent }`) in the API response (the frontend already manages displaying the full history).
        *   **Cleanup (Optional):** Implement basic cleanup for the in-memory store if needed (e.g., TTL or max size) - likely not critical for MVP.

2.  **Frontend (`pages/agents/prd-generator.tsx` & `components/agents/ChatInterface.tsx`):**
    *   **Action:** No significant changes expected, but verification needed.
    *   **Details:** Verify that the frontend correctly sends only the *new* user message in the API request body (or adjust if the backend now expects the full history - *Self-correction: The backend now manages history, so the frontend should ideally only send the new user message. Let's adjust the plan slightly.*)
    *   **Revised Frontend Logic (`pages/agents/prd-generator.tsx` handleSendMessage):** Modify the `fetch` call to send only the `newUserMessage` content, not the entire history. The backend will retrieve history from its store. `body: JSON.stringify({ message: newUserMessage })` (The API route will need to expect `message` instead of `messages` in the body).
    *   **Revised API Logic (`pages/api/agents/prd-generator.ts`):** Update the API to expect `{ message: ChatMessage }` in the request body instead of `{ messages: ChatMessage[] }`. Append this single new message to the history retrieved from the session store.

## Success Criteria

1.  The conversation starts correctly with the initial greeting.
2.  The assistant guides the user through the MVP sections sequentially (e.g., asks for exec summary, then problems/segments, then solution, then metrics, then risks/assumptions).
3.  The assistant acknowledges user input for one section before moving to the next.
4.  The conversation history is correctly maintained across multiple turns (backend state is working).
5.  The frontend correctly displays the ongoing conversation.
6.  The interaction feels reasonably natural for guiding PRD creation.

## Notes on Scope & Approach

*   Focuses primarily on backend logic for conversation flow and state.
*   Introduces simple in-memory session state (non-persistent).
*   Relies heavily on prompt engineering to guide the AI through the required sections.
*   Does *not* involve parsing structured data from the AI's responses yet.
*   Does *not* implement Markdown export (`v0.0.5e`).

## Manual Testing Steps

### 1. Full Conversation Flow
-   **Test 1.1:** Initiate and Complete MVP Flow
    -   **Action:** Start a new conversation on `/agents/prd-generator`. Engage in a multi-turn conversation, providing plausible answers for each section the assistant prompts for (Executive Summary, Problem, Segments, Solution, Metrics, Risks/Assumptions).
    -   **Expected Result:** The assistant guides the conversation logically through all the MVP sections. It should acknowledge input for one section and then prompt for the next. The conversation history should be maintained correctly throughout.
    -   **Status:** TBD

### 2. State Persistence (Conceptual)
-   **Test 2.1:** Verify History Across Requests
    -   **Action:** During the conversation flow (Test 1.1), use browser developer tools (Network tab) to inspect the payload sent *to* the API. It should only contain the single latest user message.
    -   **Action:** Add logging on the backend API route to print the retrieved history from the session store at the start of each request.
    -   **Expected Result:** Backend logs show the conversation history growing correctly with each turn, confirming state is maintained between requests (within the lifetime of the server process).
    -   **Status:** TBD

### 3. Handling Digressions (Basic Check)
-   **Test 3.1:** Ask Off-Topic Question
    -   **Action:** During the guided flow, ask an unrelated question (e.g., "What's the weather like?").
    -   **Expected Result:** The assistant might answer the question but should ideally try to steer the conversation back to the PRD generation task (e.g., "The weather is..., now back to the PRD, could you tell me about the target segments?"). Exact behavior depends on OpenAI.
    -   **Status:** TBD

### 4. Regression Checks
-   **Test 4.1:** Basic Interaction
    -   **Action:** Ensure single turns still work as in v0.0.5c.
    -   **Expected Result:** Sending a single message and receiving a reply functions correctly.
    -   **Status:** TBD
-   **Test 4.2:** Other Application Areas
    -   **Action:** Briefly check other parts of the application.
    -   **Expected Result:** No regressions introduced.
    -   **Status:** TBD 